###################################################
########## App. Dockerization Automation ##########
###################################################

#### ---------------------------------------------
#### ---- App:Specifications ----
#### ---- (DO NOT Change unless you know results)
#### ---------------------------------------------
APP_HOME=/home/developer/app
APP_MAIN=/home/developer/setup.sh

#### ---- Build Model: ---- ####
#### build models: ant maven javac jar
##APP_BUILD_MODEL=

#### ---- Command to run APP (java, python, nodejs etc.): ---- ####
#### ---- DON'T use (double) quotes for the command!      ---- ####
#### APP_RUN_CMD=python -u myproj/<FOLDER>/__main__.py
#### APP_RUN_CMD=java main.java
#### APP_RUN_CMD=node simple-server.js
#APP_RUN_CMD=sqlite_web database.db
APP_RUN_CMD=./run-sqlite-with-browser.sh

#### ---------------------------------
#### ---- App:Container:Host:Info ----
#### ---------------------------------
DOCKER_HOST_IP={{DOCKER_HOST_IP}}
DOCKER_HOST_NAME={{DOCKER_HOST_NAME}}

###################################################
########### Container-based Platform ##############
###################################################

#### -------------------------------------
#### ---- Docker:Build:Specifications ----
#### -------------------------------------
#### BUILD_VERSION=1.0.0
##USER_ID=1000
##GROUP_ID=1000
##INSTALL_BASE=/opt

#### -------------------------------------------------------------
#### ---- Docker:Run:Specifications ----
#### -------------------------------------------------------------
#### Ref: https://vsupalov.com/docker-arg-env-variable-guide/
#### Rider configuration for run.sh ####
#### - Use "#VOLUMES" and "#PORTS" to indicate that the variables for run.sh"
#### - To ignore line, use "##" (double) in the beginning, e.g. "##VOLUMES" and "##PORTS"
#### - To indicate that the variables for run.sh", use only one "#",  e.g. "#VOLUMES" and "#PORTS"

#### -------------------------------------------------------------
#### ---- Docker:Run:Specifications: Ports Mapping: ----
#### -------------------------------------------------------------
#### ---- You need to change to only 1 '#' to let "./run.sh" to interpret it.
#### PORTS_LIST="18080:8000 17200:7200"
#### PORTS_LIST="12781:12781"
#### PORTS_LIST="1234:1234/udp"
#### PORTS_LIST="8080:8080"

#### -------------------------------------------------------------
#### ---- Docker:Run:Specifications: Volumes Mapping: ----
#### -------------------------------------------------------------
#### VOLUMES_LIST="./data:data ./workspace:workspace"
#### VOLUMES_LIST="data workspace"
#### VOLUMES_LIST="app data workspace /var/run/docker.sock:/var/run/docker.sock"
#### VOLUMES_LIST="/var/run/docker.sock:/var/run/docker.sock app data workspace"
#### VOLUMES_LIST="/run/dbus:/host/run/dbus ./data:data app:/home/developer/app workspace:workspace "
#### VOLUMES_LIST="./app:app ./data:data ./workspace:workspace"
#### VOLUMES_LIST="data workspace /dev/shm:/dev/shm /var/run/docker.sock:/var/run/docker.sock /tmp/.X11-unix:/tmp/.X11-unix"


#####################################
#### ---- NVIDIA Variables: ---- ####
#####################################
#### ref: https://github.com/NVIDIA/nvidia-docker/wiki/Installation-(Native-GPU-Support)#usage
#### set both NVIDIA_VISIBLE_DEVICES and NVIDIA_VISIBLE_DEVICES with GPU-IDs to control the GPUs available inside the container
##TOKENIZERS_PARALLELISM=true
##NVIDIA_VISIBLE_DEVICES=all
##NVIDIA_VISIBLE_DEVICES=0
##CUDA_VISIBLE_DEVICES=0
##NVIDIA_DRIVER_CAPABILITIES=compute,video,utility

##LD_LIBRARY_PATH=/usr/local/cudnn/lib64:/usr/local/cuda/lib64:\${LD_LIBRARY_PATH}

#############################################################################
#### --- TO-DO HERE: Modify the line below to open the ports mapping: -- ####
#############################################################################
##VOLUMES_LIST="data workspace /dev/shm:/dev/shm /var/run/docker.sock:/var/run/docker.sock"
##VOLUMES_LIST="data workspace /usr/local/cuda/lib64:/usr/local/cuda/lib64"
##VOLUMES_LIST="./app/tfhub:/home/developer/tfhub data workspace /usr/local/cuda/lib64:/usr/local/cuda/lib64 /usr/local/cudnn/lib64:/usr/local/cudnn/lib64 /dev/shm:/dev/shm /var/run/docker.sock:/var/run/docker.sock
## VOLUMES_LIST="./app/huggingface:/home/developer/app/huggingface data workspace /usr/local/cuda/lib64:/usr/local/cuda/lib64 /usr/local/cudnn/lib64:/usr/local/cudnn/lib64 /dev/shm:/dev/shm /var/run/docker.sock:/var/run/docker.sock
##VOLUMES_LIST="data workspace ./app/torch:/home/developer/app/torch"
##VOLUMES_LIST="data workspace ./app/huggingface:/home/developer/app/huggingface"
##VOLUMES_LIST="./app-data:/home/developer/app/data workspace"

#VOLUMES_LIST=" data workspace"

#PORTS_LIST="10808:8080"

########################################
#### ---- Certificates Vars:   ---- ####
########################################
#### ---- certificate(s): needed by Transformer hub download PyTorch request: ---- ####
##REQUESTS_CA_BUNDLE=/certificates/some.crt
##SSL_DISABLE_VERIFICATION=1

################################################
#### ---- REST API-Specific Variables: ---- ####
################################################
#### choices: [flask, gradio]
##FLASK_OR_GRADIO=flask

#####################################
#### ---- UNIT Test Vars:   ---- ####
#####################################
##UNIT_TEST=0

